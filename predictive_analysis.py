# -*- coding: utf-8 -*-
"""predictive-analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rM_Izqlkae6nSrcmBxLRLuYUkRmpg60T
"""

!pip install -U scikit-learn==1.3.2 imbalanced-learn==0.11.0

"""## **Import Library**"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import sklearn
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.preprocessing import StandardScaler
from scipy.stats import chi2_contingency
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import warnings
warnings.filterwarnings('ignore')

"""## **Data Loading**"""

dataset = pd.read_csv("/kaggle/input/mecfs-vs-depression-classification-dataset/me_cfs_vs_depression_dataset.csv")

# Menghitung jumlah baris dan kolom dalam DataFrame
jumlah_ulasan, jumlah_kolom = dataset.shape

print("Jumlah ulasan:", jumlah_ulasan)
print("Jumlah kolom:", jumlah_kolom)

dataset.head()

"""Output kode di atas memberikan informasi sebagai berikut:

* Terdapat **1.000 baris** dalam dataset.
* Terdapat **16 kolom** yaitu: **age**, **gender**, **sleep_quality_index**, **brain_fog_level**, **physical_pain_score**, **stress_level**, **depression_phq9_score**, **fatigue_severity_scale_score**, **pem_duration_hours**, **hours_of_sleep_per_night**, **pem_present**, **work_status**, **social_activity_level**, **exercise_frequency**, **meditation_or_mindfulness**, dan **diagnosis**.

## **Exploratory Data Analysis**

### **Deskripsi Variabel**

**Informasi data**

| Nama Fitur            | Keterangan                          |
|-----------------------|-------------------------------------|
| age                   | Usia pasien                         |
| gender                | Jenis kelamin (Male / Female / Other)|
| fatigue_severity_scale_score | Skala tingkat keparahan kelelahan (FSS) (skala 0–10) |
| depression_phq9_score | Skor depresi PHQ-9 (skala 0–27)     |
| pem_present           | Apakah ada Post-Exertional Malaise (PEM)? (Yes/No atau 1/0)|
| pem_duration_hours    | Lama durasi PEM dalam jam           |
| sleep_quality_index   | Kualitas tidur (skala 1–10)         |
| brain_fog_level       | Tingkat brain fog (skala 1–10)      |
| physical_pain_score   | Intensitas nyeri tubuh yang dirasakan pasien (skala 1–10) |
| stress_level          | Tingkat stres (skala 1–10)          |
| work_status           | Status pekerjaan pasien (Working / Partially working / Not working) |
| social_activity_level | Tingkat keterlibatan dalam aktifitas sosial (Very low – Very high) |
| exercise_frequency    | Frekuensi berolahraga (Never – Daily) |
| meditation_or_mindfulness| Apakah pasien sering melakukan praktek kesadaran diri/meditasi? Yes/No |
| hours_of_sleep_per_night | Rata-rata jam tidur per malam    |
| diagnosis                | Diagnosis akhir pasien (ME/CFS, Depression, Both) |
"""

# Menampilkan informasi
dataset.info()

"""Dari output terlihat bahwa:

* Terdapat 6 kolom dengan tipe object, yaitu: gender, work_status, social_activity_level, exercise_frequency, meditation_or_mindfulness, dan diagnosis. Kolom ini merupakan categorical features (fitur non-numerik).
* Terdapat 2 kolom numerik dengan tipe data int64, yaitu: age dan pem_present
* dan sisanya sebanyak 8 kolom numerik  bertipe data float64.
"""

# Memeriksa duplikasi dan ringkasan parameter statistik
print("Jumlah duplikasi: ", dataset.duplicated().sum())
dataset.describe()

"""Dari output terlihat bahwa:
* Tidak terdapat duplikasi data pada dataset
* Rata-rata pasien berumur 44.39 tahun, dimana pasien termuda berusia 18 tahun dan tertua 70 tahun.
* Rata-rata pasien memiliki kualitas tidur menengah ke atas, yaitu 5.47.
* Mayoritas pasien mengalami tingkat brain fog di level sedang ke atas, yaitu 5.61. Hal ini sudah masuk area "mengganggu fungsi harian".
* Rata-rata intensitas nyeri fisik yang dirasakan pasien berada di level sedang ke atas, yaitu 5.52.
* Tingkat stres mayoritas pasien berada di level sedang ke atas, yaitu 5.46.
* Mayoritas pasien kemungkinan besar memiliki gejala depresi tingkat sedang.
* Rata-rata pasien mengalami kelelahan yang tinggi dan mengganggu fungsi sehari-hari.
* Rata-rata pasien mengalami crash setelah aktivitas fisik atau mental dan tidak bisa pulih hanya dengan istirahat singkat. Hal ini karena rata-rata durasi PEM yang dirasakan mencapai 23 jam.
* Rata-rata jam tidur pasien adalah 6.57, yang berarti peserta tidak mencapai durasi tidur yang optimal.
* 59% dari pasien mengalami Post-Exertional Malaise (PEM).

### **Menangani Missing Value**
"""

# Mengecek missing value
dataset.isna().sum()

"""Berdasarkan hasil output tersebut, terdapat 12 fitur yang memiliki missing value. Selain itu, dari pengamatan yang telah dilakukan, diketahui bahwa fitur depression_phq9_score dan pem_present memiliki keterkaitan yang berpotensi berkontribusi terhadap penentuan diagnosis. Oleh karena itu, akan dilakukan pengecekan pada kedua fitur."""

# Menghitung jumlah diagnosis berdasarkan kolom depression_phq9_score
counts_dps = dataset.groupby('depression_phq9_score')['diagnosis'].value_counts()
counts_dps

# Menghitung jumlah diagnosis berdasarkan kolom pem_present
counts_pp = dataset.groupby('pem_present')['diagnosis'].value_counts()
counts_pp

"""Berdasarkan output di atas, diketahui bahwa:
* Hasil diagnosis menunjukkan **depression** ketika nilai **depression_phq9_score >= 10** dan **pem_present = 0**
* Hasil diagnosis menunjukkan **ME/CFS** ketika nilai **depression_phq9_score < 10** dan **pem_present = 1**
* Hasil diagnosis menunjukkan **both** ketika nilai **depression_phq9_score >= 10** dan **pem_present = 1**

Dengan begitu, imputasi yang dilakukan pada fitur depression_phq9_score akan mempertimbangkan diagnosis logis diatas.
"""

# Mengatasi missing value pada fitur depression_phq9_score
# Membuat mask berdasarkan diagnosis logis
mask_depression = (dataset['pem_present'] == 0)
mask_mecfs = (dataset['pem_present'] == 1) & (dataset['depression_phq9_score'] < 10)
mask_both = (dataset['pem_present'] == 1) & (dataset['depression_phq9_score'] >= 10)

# Menghitung nilai median untuk setiap kelompok diagnosis logis
median_dep = dataset.loc[mask_depression, 'depression_phq9_score'].median()
median_mecfs = dataset.loc[mask_mecfs, 'depression_phq9_score'].median()
median_both = dataset.loc[mask_both, 'depression_phq9_score'].median()

# Membuat fungsi imputasi
def isi_phq9(row):
    if pd.isna(row['depression_phq9_score']):
        if row['pem_present'] == 0:
            return median_dep
        elif row['pem_present'] == 1:
            return median_mecfs

    return row['depression_phq9_score']

# Menerapkan fungsi imputasi untuk mengisi nilai NaN pada kolom 'depression_phq9_score'
dataset['depression_phq9_score'] = dataset.apply(isi_phq9, axis=1)

dataset.info()

# Menghapus fitur lainnya yang mengandung missing value
dataset_clean = dataset.dropna()
print(f"Jumlah baris setelah dibersihkan: {len(dataset_clean)} dari {len(dataset)}")

# Menghitung proporsi fitur diagnosis sebelum missing value dihapus
dataset['diagnosis'].value_counts(normalize=True)

# Menghitung proporsi fitur diagnosis setelah missing value dihapus
dataset_clean['diagnosis'].value_counts(normalize=True)

"""Dari output tersebut, diketahui bahwa perubahan yang terjadi berada di bawah 1%, menunjukkan bahwa penghapusan baris yang mengandung NaN tidak secara drastis mengganggu distribusi diagnosis."""

dataset_clean.info()

"""### **Menangani Outlier**"""

# Membagi fitur pada dataset menjadi dua bagian
numerical_features = ['age', 'sleep_quality_index', 'brain_fog_level', 'physical_pain_score', 'stress_level', 'depression_phq9_score',
                      'fatigue_severity_scale_score', 'pem_duration_hours', 'hours_of_sleep_per_night', 'pem_present']
categorical_features = ['gender', 'work_status', 'social_activity_level', 'exercise_frequency',
                        'meditation_or_mindfulness', 'diagnosis']

# Visualisasi dengan boxplot untuk mendeteksi outliers pada fitur numerik
plt.figure(figsize=(15, 12))
for i, col in enumerate(numerical_features, 1):
    plt.subplot(4, 3, i)
    sns.boxplot(x=dataset_clean[col], color='steelblue')
    plt.title(f'Outlier pada {col}')
    plt.xlabel(col)

plt.tight_layout()
plt.show()

"""Berdasarkan hasil analisis terhadap fitur numerik, terdapat 2 fitur yang memiliki outlier, yaitu fitur **depression_phq9_score** dan **fatigue_severity_scale_score**. Meskipun demikian, tidak akan dilakukan penanganan terhadap outlier tersebut, mengingat outlier masih berada dalam range nilai yang diharapkan dari tiap fitur, yaitu **depression_phq9_score** dengan nilai antara **0 hingga 27** dan **fatigue_severity_scale_score** dengan nilai antara **0 hingga 10**.

### **Univariate Analysis**

* **Categorical Features**
"""

# Fitur gender
feature = categorical_features[0]
count = dataset_clean[feature].value_counts()
percent = 100 * dataset_clean[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Berdasarkan output tersebut, diketahui bahwa dataset ini terdiri dari **343 pasien berjenis kelamin laki-laki (50.2%)** dan **340 pasien berjenis kelamin perempuan (49.8%)**. Hal ini menunjukkan bahwa distribusi gender pada dataset ini hampir seimbang, meskipun laki-laki sedikit lebih dominan.

"""

# Fitur work_status
feature = categorical_features[1]
count = dataset_clean[feature].value_counts()
percent = 100 * dataset_clean[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Berdasarkan output tersebut, diketahui bahwa **36.6% pasien** masih bisa bekerja walaupun tidak secara penuh **(partially working)**, **33.4% pasien** bekerja secara penuh **(working)**, dan sisanya tidak bekerja sama sekali **(not working)**."""

# Fitur social_activity_level
feature = categorical_features[2]
count = dataset_clean[feature].value_counts()
percent = 100 * dataset_clean[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Berdasarkan output tersebut, diketahui bahwa:
* Terdapat **21.2% pasien** yang terlibat aktif mengikuti aktifitas sosial.
* Terdapat **40.8% (very low + low) pasien** yang cukup banyak mengalami penarikan sosial ekstrem atau keterlibatan sosial yang rendah.
* Terdapat **19.3% pasien** yang sangat aktif bersosialisasi.
"""

# Fitur exercise_frequency
feature = categorical_features[3]
count = dataset_clean[feature].value_counts()
percent = 100 * dataset_clean[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Berdasarkan output tersebut, diketahui bahwa:
* Mayoritas pasien menunjukkan kebiasaan yang sehat dan aktif berolahraga, yaitu sebesar **42.8% pasien (Daily + Often)**.
* Disisi lain, **20.4% pasien** jarang melakukan olahraga, **19.9% pasien** terkadang masih melakukan olahraga, dan sisanya **17% pasien** tidak pernah melakukan aktifitas olahraga.

"""

# Fitur meditation_or_mindfulness
feature = categorical_features[4]
count = dataset_clean[feature].value_counts()
percent = 100 * dataset_clean[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Berdasarkan output tersebut, diketahui bahwa **50.4% pasien** melakukan praktek kesadaran diri/meditasi dan sisanya tidak melakukan praktek tersebut."""

# Fitur diagnosis
feature = categorical_features[5]
count = dataset_clean[feature].value_counts()
percent = 100 * dataset_clean[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Berdasarkan output tersebut, diketahui bahwa:
* Terdapat **40.3% pasien** yang didiagnosa **depression**.
* Terdapat **38.8% pasien** yang didiagnosa **ME/CFS**.
* dan sisanya, **didiagnosa keduanya**.

* **Numerical Features**
"""

# Melihat histogram dari masing-masing fitur numerik
dataset_clean.hist(bins=50, figsize=(20,15))
plt.show()

"""Berdasarkan output tersebut, diketahui:
* Pola usia bervariasi, dengan puncak sekitar usia 20, 40, dan 70 tahun.
* Fitur sleep_quality_index dan brain_fog_level memiliki nilai yang tersebar merata antara 0–10, menandakan variasi yang luas dalam kualitas tidur dan kejernihan kognitif.
* Distribusi dari fitur physical_pain_score dan stress_level relatif seimbang, tapi ada konsentrasi ringan di rentang tengah hingga tinggi, mengindikasikan kelelahan fisik dan tekanan emosional cukup umum.
* Fitur depression_phq9_score menunjukkan lonjakan jelas di sekitar skor 10.
* Fitur fatigue_severity_scale_score didominasi nilai tinggi, terutama di angka 7 yang menandakan sebagian besar individu mengalami kelelahan cukup parah.
* Durasi Post-Exertional Malaise (PEM) bervariasi luas tanpa pola puncak tertentu.
* Jam tidur per malam terdistribusi cukup merata dari 3 hingga 10 jam, mengindikasikan pola tidur yang tidak seragam.
* Mayoritas individu mengalami PEM (nilai 1).

### **Multivariate Analysis**

* **Numerical Features**
"""

plt.figure(figsize=(12, 8))
sns.heatmap(dataset_clean[numerical_features].corr(), annot=True, cmap='coolwarm')
plt.tight_layout()
plt.show()

"""Berdasarkan output tersebut, diketahui:
* Mayoritas fitur numerik dalam dataset tidak memiliki hubungan linear yang kuat satu sama lain (r < 0.3). Hal ini mengindikasikan bahwa setiap fitur mungkin menyumbang informasi unik terhadap model tanpa tumpang tindih signifikan.
* Korelasi Pearson antara sleep_quality_index dan physical_pain_score sebesar 0.11, menunjukkan adanya hubungan linear yang sangat lemah. Jika sleep_quality_index meningkat, physical_pain_score cenderung meningkat sedikit juga, tapi hubungan ini sangat lemah.
* Nilai korelasi antara pem_present dan depression_phq9_score adalah –0.34, yang menunjukkan hubungan negatif lemah hingga sedang secara linear. Hal ini berarti, semakin tinggi kemungkinan seseorang mengalami PEM (Post-Exertional Malaise), cenderung semakin rendah skor depresi PHQ-9-nya, dan begitu juga sebaliknya.
* Korelasi antara fatigue_severity_scale_score dan pem_present sebesar 0.58, yang menunjukkan hubungan moderat hingga kuat secara linear. Hal ini berarti semakin tinggi tingkat kelelahan seseorang, maka semakin besar kemungkinan seseorang tersebut mengalami PEM.

* **Categorical Features**
"""

def cramers_v_matrix(df_cat):
    cols = df_cat.columns
    matrix = pd.DataFrame(np.zeros((len(cols), len(cols))), index=cols, columns=cols)
    for col1 in cols:
        for col2 in cols:
            confusion = pd.crosstab(df_cat[col1], df_cat[col2])
            chi2 = chi2_contingency(confusion)[0]
            n = confusion.sum().sum()
            phi2 = chi2 / n
            r, k = confusion.shape
            matrix.loc[col1, col2] = np.sqrt(phi2 / min(k-1, r-1))
    return matrix

cramer_matrix = cramers_v_matrix(dataset_clean[categorical_features])

plt.figure(figsize=(8,6))
sns.heatmap(cramer_matrix, annot=True, cmap="YlOrBr")

"""Berdasarkan output di atas, diketahui:
- Mayoritas nilai Cramér's V berada di bawah 0.1, yang mengindikasikan bahwa hubungan antar variabel kategorikal dalam dataset ini sangat lemah atau hampir tidak ada.
- Pasangan dengan asosiasi tertinggi adalah:
  - social_activity_level dan diagnosis: 0.10
  - exercise_frequency dan diagnosis: 0.087
  - social_activity_level dan exercise_frequency: 0.085
- Variabel gender dan diagnosis memiliki nilai Cramér's V terendah (0.0067), menunjukkan tidak ada asosiasi yang berarti antara jenis kelamin dan diagnosis dalam data ini.

"""

# Menghapus fitur gender dan meditation_or_mindfulness yang memiliki korelasi yang sangat kecil dengan diagnosis
dataset_clean.drop(['gender', 'meditation_or_mindfulness'], inplace=True, axis=1)
dataset_clean.head()

"""### **Data Preparation**"""

# Mengubah fitur kategori menjadi fitur numerik
# dataset_clean['gender'] = dataset_clean['gender'].map({'Female': 1, 'Male': 0})
# dataset_clean['meditation_or_mindfulness'] = dataset_clean['meditation_or_mindfulness'].map({'Yes': 1, 'No': 0})
dataset_clean = pd.concat([dataset_clean, pd.get_dummies(dataset_clean['work_status'], prefix='work_status').astype(int)],axis=1)
dataset_clean = pd.concat([dataset_clean, pd.get_dummies(dataset_clean['social_activity_level'], prefix='social_activity_level').astype(int)],axis=1)
dataset_clean = pd.concat([dataset_clean, pd.get_dummies(dataset_clean['exercise_frequency'], prefix='exercise_frequency').astype(int)],axis=1)

# Menghapus kolom work_status hingga kolom exercise_frequency
dataset_clean.drop(['work_status','social_activity_level','exercise_frequency'], axis=1, inplace=True)
dataset_clean.head()

"""### **Train-Test-Split**"""

# Mengubah fitur diagnosis menjadi fitur numerik
le = LabelEncoder()
dataset_clean['diagnosis_encoded'] = le.fit_transform(dataset_clean['diagnosis'])
dataset_clean.head()

X = dataset_clean.drop(["diagnosis", "diagnosis_encoded"],axis =1)
y = dataset_clean["diagnosis_encoded"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)

X.info()

# Visualisasi untuk melihat distribusi label pada data pelatihan
sns.countplot(x=y_train)

# Menerapkan SMOTE pada data pelatihan
smote = SMOTE(sampling_strategy={0: 200}, random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

print("Distribusi label setelah SMOTE:", Counter(y_train))

"""Dalam penanganan imbalanced dataset, ukuran kelas minoritas (kelas both (0)) tidak disamakan dengan kelas mayoritas. Hal ini bertujuan untuk meningkatkan representasi kelas minoritas tanpa menciptakan distorsi distribusi yang tidak realistis, sehingga proporsi data tetap mendekati kondisi dunia nyata dan model dapat belajar dari data yang lebih seimbang namun tetap mencerminkan kompleksitas sebenarnya dari populasi klinis.

### **Standarisasi**
"""

# Memisahkan fitur pem_present dengan fitur numerik lainnya
binary_cols = ['pem_present']
scale_cols = [col for col in X_train[numerical_features] if col not in binary_cols]

scaler = StandardScaler()
X_train_scaled = X_train.copy()
scaled_array = scaler.fit_transform(X_train[scale_cols])
scaled_df = pd.DataFrame(scaled_array, columns=scale_cols, index=X_train.index)

# Menggabungkan kembali fitur pem_present dengan fitur numerik lainnya
X_final = pd.concat([scaled_df, X_train[binary_cols]], axis=1)
X_final.head()

"""Standarisasi dilakukan pada semua fitur numerik kecuali fitur pem_present, mengingat fitur tersebut hanya terdiri dari dua nilai, yaitu 0 dan 1. Hal ini dilakukan agar makna yang terkandung dalam fitur tersebut tetap terjaga, serta agar model klasifikasi dapat menginterpretasikannya secara eksplisit tanpa menyamarkannya dalam skala numerik yang tidak relevan."""

X_final.describe().round(4)

"""Berdasarkan output di atas, diketahui bahwa standarisasi telah berhasil dilakukan, terlihat dari nilai mean=0 dan standar deviasi=1 untuk semua fitur numerik kecuali fitur pem_present."""

# Mendeteksi kolom kategorikal hasil one-hot encoding
categorical_cols = [col for col in X_train.columns if col not in set(scale_cols + binary_cols)]
encoded_cats = X_train[categorical_cols]

# Menggabungkan numerik yang sudah distandarisasi + fitur kategorikal
X_train_final = pd.concat([X_final, encoded_cats], axis=1)
X_train_final.head()

"""### **Model Development**

* **K-nearest neighbors (KNN)**
"""

# Inisialisasi model
knn = KNeighborsClassifier(n_neighbors=5)

# Train model
knn.fit(X_train_final, y_train)

# Prediksi
y_pred_train_knn = knn.predict(X_train_final)

# Evaluasi akurasi model XGBoost
accuracy_train_knn = accuracy_score(y_train, y_pred_train_knn)

# Menampilkan akurasi
print('KNN - accuracy_train:', accuracy_train_knn)

"""* **AdaBoost**"""

# X_train_final = X_train_final[boosting.feature_names_in_]

# Inisialisasi model
boosting = AdaBoostClassifier(
    n_estimators=50,
    algorithm='SAMME.R',
    random_state=42)

# Train model
boosting.fit(X_train, y_train)

# Prediksi
y_pred_train_boosting = boosting.predict(X_train_final)

# Evaluasi akurasi model AdaBoost
accuracy_train_boosting = accuracy_score(y_train, y_pred_train_boosting)

# Menampilkan akurasi
print('AdaBoost - accuracy_train:', accuracy_train_boosting)

"""* **Random Forest**"""

# Inisialisasi model
RF = RandomForestClassifier(criterion='gini', n_estimators=100, max_depth=9, random_state=44)

# Train model
RF.fit(X_train_final, y_train)

# Prediksi
y_pred_train_rf = RF.predict(X_train_final)

# Evaluasi akurasi model XGBoost
accuracy_train_rf = accuracy_score(y_train, y_pred_train_rf)

# Menampilkan akurasi
print('Random Forest - accuracy_train:', accuracy_train_rf)

importances = pd.Series(RF.feature_importances_, index=X_train_final.columns).sort_values(ascending=False)
importances

"""* **XGBoost**"""

import xgboost as xgb

# Inisialisasi model
XGBoost = xgb.XGBClassifier(objective="multi:softprob", eval_metric="mlogloss", n_estimators=100,
                         learning_rate=0.1, reg_alpha=0.5, reg_lambda=0.5)

# Train model
XGBoost.fit(X_train_final, y_train)

# Prediksi
y_pred_train_xgb = XGBoost.predict(X_train_final)

# Evaluasi akurasi model XGBoost
accuracy_train_xgb = accuracy_score(y_train, y_pred_train_xgb)

# Menampilkan akurasi
print('XGBoost - accuracy_train:', accuracy_train_xgb)

# Plot importance
xgb.plot_importance(XGBoost, importance_type='gain')  # mengetahui rata-rata peningkatan akurasi ketika fitur digunakan
plt.tight_layout()
plt.show()

"""### **Evaluasi Model**"""

# Transformasi data test menggunakan scaler dari training
scaled_array_test = scaler.transform(X_test[scale_cols])
scaled_df_test = pd.DataFrame(scaled_array_test, columns=scale_cols, index=X_test.index)

# Gabungkan kembali dengan kolom biner
X_test_final = pd.concat([scaled_df_test, X_test[binary_cols]], axis=1)
X_test_final.head()

encoded_cols_test = X_test[categorical_cols]

# Reset index untuk memastikan tidak ada duplikat atau inkonsistensi
X_test_final = X_test_final.reset_index(drop=True)
encoded_cats = encoded_cols_test.reset_index(drop=True)

# Gabungkan numerik yang sudah distandarisasi + fitur kategorikal
X_test_final = pd.concat([X_test_final, encoded_cats], axis=1)
X_test_final.head()

# Evaluasi KNN
y_pred_knn = knn.predict(X_test_final)
print("KNN Performance:")
print(classification_report(y_test, y_pred_knn))

# X_test_final = X_test_final[boosting.feature_names_in_]

# Evaluasi AdaBoost
y_pred_boosting = boosting.predict(X_test_final)
print("AdaBoost Performance:")
print(classification_report(y_test, y_pred_boosting))

# Evaluasi Random Forest
y_pred_rf = RF.predict(X_test_final)
print("Random Forest Performance:")
print(classification_report(y_test, y_pred_rf))

# Evaluasi XGBoost
y_pred_xgb = XGBoost.predict(X_test_final)
print("XGBoost Performance:")
print(classification_report(y_test, y_pred_xgb))

# Evaluasi Random Forest
print("\nEvaluasi Random Forest:")
print(f"Akurasi: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Presisi: {precision_score(y_test, y_pred_rf, average='macro'):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf, average='macro'):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_rf, average='macro'):.4f}")

# Evaluasi XGBoost
print("\nEvaluasi XGBoost:")
print(f"Akurasi: {accuracy_score(y_test, y_pred_xgb):.4f}")
print(f"Presisi: {precision_score(y_test, y_pred_xgb, average='macro'):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_xgb, average='macro'):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_xgb, average='macro'):.4f}")

# Mengacak fitur tertentu untuk menguji sensitivitas model
X_train_shuffled = np.random.permutation(X_train_final)
XGBoost.fit(X_train_shuffled, y_train)
print(f"Akurasi XGBoost dengan Fitur Acak: {XGBoost.score(X_test_final, y_test):.4f}")

RF.fit(X_train_shuffled, y_train)
print(f"Akurasi Random Forest dengan Fitur Acak: {RF.score(X_test_final, y_test):.4f}")

"""Jika dilihat dari output di atas, diketahui bahwa hasil evaluasi untuk algoritma Random Forest dan XGBoost adalah 1.00.
Namun, setelah fitur diacak, akurasi model mengalami penurunan secara drastis. Hal ini mengindikasikan bahwa fitur tersebut sebelumnya memiliki kontribusi prediktif yang signifikan. Jika terjadi data leakage, model justru akan menunjukkan performa yang terlalu tinggi secara tidak wajar, bukan mengalami degradasi performa ekstrem saat fitur diganggu. Oleh karena itu, kemungkinan besar hasil evaluasi yang sempurna ini bukan disebabkan oleh data leakage.
"""